{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Process Individual Fire Workspace<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYST ACTION: paste IR camera data to \"/_camera_data/\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 1 ### Optional: open ABWF web dashboard\n",
    "\n",
    "import webbrowser\n",
    "AB_wildfire_link = 'https://www.arcgis.com/apps/dashboards/3ffcc2d0ef3e4e0999b0cf8b636defa3'\n",
    "webbrowser.open(AB_wildfire_link)\n",
    "print(\"COMPLETED - browser window opened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 2 ### Input outside variables\n",
    "\n",
    "fireName = input(\"fire name, if no name exists leave empty\")\n",
    "\n",
    "import re\n",
    "def scan_time_validator():\n",
    "    while True:\n",
    "        time = input(\"24HR time. Format: '0200'\")\n",
    "        pattern = r\"[0-2][0-9][0-9][0-9]\"\n",
    "        if re.match(pattern, time):\n",
    "            return time\n",
    "        else:\n",
    "            assert False,\"ERROR: invalid time format, please try input again\"\n",
    "\n",
    "# Example usage\n",
    "captureTime = scan_time_validator()\n",
    "\n",
    "#captureTime = input(\"24HR time. Format: '0200'\")\n",
    "if fireName == \"\":\n",
    "    fireName = \"None entered\"\n",
    "\n",
    "print(f\"COMPLETED - Fire name: {fireName} | Capture time: {captureTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYST ACTION: input fire (if exists) and fire scan start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 3 ### Assign file names and directory paths\n",
    "\n",
    "productionDirectory = r\"C:\\Verimap-IRmapper\\.Alberta_mapping\\production_workspace\"\n",
    "gdrive = r\"G:\\Shared drives\\GIS Data Center\\Delivered To The Goverment\\Alberta_deliverables\"\n",
    "\n",
    "import datetime, os\n",
    "#Generate datetimes\n",
    "delivery_date_raw = datetime.date.today()\n",
    "delivery_date = delivery_date_raw.strftime('%y%m%d')\n",
    "if int(captureTime) > 1600:\n",
    "    scan_date_raw = delivery_date_raw - datetime.timedelta(days = 1)\n",
    "else:\n",
    "    scan_date_raw = delivery_date_raw\n",
    "\n",
    "#Capture name of this fire from file name\n",
    "script_name = os.path.basename(globals()['__vsc_ipynb_file__'])\n",
    "fireID = script_name[:6]\n",
    "if fireName == None:\n",
    "    fireName = fireID \n",
    "\n",
    "## folder paths\n",
    "masterFireDir = f'{productionDirectory}/{delivery_date}/{fireID}_{delivery_date}'\n",
    "deliverablesDir = f'{masterFireDir}/{fireID}'\n",
    "rawSensorDataDir = f'{productionDirectory}/{delivery_date}/_camera_data_{delivery_date}/{fireID}'\n",
    "recentFirePerimeterFilepath = f'{masterFireDir}/Scratch/{fireID}_request_perimeter.shp'\n",
    "\n",
    "## BUILD FILE NAMES\n",
    "breadcrumbFileName = f'{fireID}{delivery_date[2:]}{captureTime[:2]}b'\n",
    "hotspotsFileName = f'{fireID}{delivery_date[2:]}{captureTime[:2]}h'\n",
    "perimeterFileName = f'{fireID}{delivery_date[2:]}{captureTime[:2]}p'\n",
    "imageryFileName = f'{fireID}{delivery_date[2:]}{captureTime[:2]}i'\n",
    "\n",
    "print(f\"COMPLETED - all file names and folder paths assigned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 4 ### Push initial data to directories\n",
    "\n",
    "import shutil\n",
    "## Build deliverables directory\n",
    "if fireID in os.listdir(masterFireDir):\n",
    "   shutil.rmtree(deliverablesDir)\n",
    "os.mkdir(deliverablesDir)\n",
    "\n",
    "# Build data directories\n",
    "for dir in ['Breadcrumb','Hotspots','Perimeter','QuicklookMap','Thermal_Imagery']:\n",
    "   if dir not in os.listdir(deliverablesDir):\n",
    "      os.mkdir(f\"{deliverablesDir}/{dir}\")\n",
    "\n",
    "# Move files into appropriate locations\n",
    "for file in os.scandir(f'{rawSensorDataDir}'):\n",
    "   if file.name.endswith('.csv'):\n",
    "      shutil.copy(file.path, f'{masterFireDir}/Scratch/{hotspotsFileName}.csv')\n",
    "   if file.name.endswith('.kml'):\n",
    "      shutil.copy(file.path, f'{masterFireDir}/Scratch/{breadcrumbFileName}.kml')\n",
    "   if file.name.endswith('.tif'):\n",
    "      shutil.copy(file.path, f'{deliverablesDir}/Thermal_Imagery/{imageryFileName}.tif')\n",
    "\n",
    "open(f\"{deliverablesDir}/QuicklookMap/{fireID}{delivery_date}HotspotDetection.pdf\", \"w+\")\n",
    "\n",
    "print(\"COMPLETED - Files are copied successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 5 ### Clean and produce breadcrumb files\n",
    "\n",
    "import geopandas, simplekml, fiona\n",
    "# Read the beadcrumb KML file into a GeoDataFrame\n",
    "kml_file = f\"{masterFireDir}/Scratch/{breadcrumbFileName}.kml\"\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "#geopandas.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "gdf_breadcrumb = geopandas.read_file(kml_file, driver='KML')\n",
    "gdf_breadcrumb.drop(1, axis=0, inplace=True)\n",
    "gdf_breadcrumb.at[0,'Description'] = f\"{fireID}\"\n",
    "\n",
    "# Write the GeoDataFrame to a shapefile\n",
    "gdf_breadcrumb_3400 = gdf_breadcrumb.to_crs(3400)\n",
    "gdf_breadcrumb_3400.to_file(f'{deliverablesDir}/Breadcrumb/{breadcrumbFileName}.shp', driver='ESRI Shapefile')\n",
    "\n",
    "# Extract geometry data\n",
    "gdf_breadcrumb['points'] = gdf_breadcrumb.apply(lambda x: [y for y in x['geometry'].coords], axis=1)\n",
    "lineString = gdf_breadcrumb.iloc[0]['points']\n",
    "lineStringList = gdf_breadcrumb.iloc[0]['points']\n",
    "\n",
    "# Create an instance of Kml\n",
    "kml = simplekml.Kml(open=1)\n",
    "\n",
    "# Create a linestring with two points (ie. a line)\n",
    "lin = kml.newlinestring(name=\"Flight Path\")\n",
    "lin.coords = lineStringList\n",
    "lin.style.linestyle.color = 'ff800080'\n",
    "lin.style.linestyle.width = 2\n",
    "\n",
    "kml.save(f'{deliverablesDir}/Breadcrumb/{breadcrumbFileName}.kml')\n",
    "\n",
    "print(\"COMPLETED - Breadcrumb files were generated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 6 ### Clean and produce initial hotspot shapefile\n",
    "\n",
    "import pandas\n",
    "hotSpotTextFile = f'{masterFireDir}/Scratch/{hotspotsFileName}.csv'\n",
    "df_hotSpots = pandas.read_csv(hotSpotTextFile, sep=\",\", header=None)\n",
    "df_hotSpots.columns = df_hotSpots.iloc[0]\n",
    "\n",
    "# Parse hotspots CSV table\n",
    "if df_hotSpots.columns[0] == \"Label\":\n",
    "    print(\"standard CSV\")\n",
    "    #Ingest standard hotspot CSV\n",
    "    df_hotSpots = df_hotSpots.drop(0).drop(columns=[\"Label\", \"DDM_lat\", \"DDM_long\"], axis=1).dropna(axis=1)\n",
    "    df_hotSpots.columns = [\"HotspotID\",\"Latitude\",\"Longitude\",\"HeatScore\"]\n",
    "elif df_hotSpots.columns[0] == \"Index\":\n",
    "    print(\"highres CSV\")\n",
    "    #Ingesting hotspotting CSV table\n",
    "    df_hotSpots = df_hotSpots.drop(0).drop(columns=[\"Threshold\",\"filename\",\"col\",\"row\"], axis=1).dropna(axis=1)\n",
    "    df_hotSpots.columns = [\"HotspotID\",\"HeatScore\",\"Class\",\"Longitude\",\"Latitude\"]\n",
    "else:\n",
    "    print(\"Hotspots CSV is a non-standard format\")\n",
    "\n",
    "df_hotSpots = df_hotSpots.astype({\"HotspotID\": \"int64\", \n",
    "                                  \"Latitude\": \"float32\", \n",
    "                                  \"Longitude\": \"float32\", \n",
    "                                  \"HeatScore\": \"float32\"})\n",
    "x = scan_date_raw.strftime('%d-%b-%y')\n",
    "\n",
    "templateColumns = {\n",
    "    'Heat': 'HOTSPOT',\n",
    "    'Fire_Num': f'{fireID}',\t\n",
    "    'Fire_Name': f'{fireName}',\t\n",
    "    'CaptureDat': f'{x}',\t\n",
    "    'CaptureTim': f'{captureTime[:2]}:{captureTime[2:]}:00',\t\n",
    "    'Agency': 'Verimap Plus Inc',\n",
    "    'Comments': f'{fireName}',\t\n",
    "    'Contact': 'Amir Paz',\t\n",
    "    'Phone': '403-464-3059',\t\n",
    "    'Email': 'apaz@verimap.com'\t\n",
    "}\n",
    "\n",
    "for pair in templateColumns:\n",
    "    df_hotSpots[pair] = templateColumns[pair]\n",
    "\n",
    "gdf_hotSpots = geopandas.GeoDataFrame(\n",
    "    df_hotSpots, geometry= geopandas.points_from_xy(df_hotSpots.Longitude, \n",
    "                                             df_hotSpots.Latitude), \n",
    "                                             crs=\"EPSG:4269\")\n",
    "gdf_hotSpots = gdf_hotSpots.to_crs(3400)\n",
    "\n",
    "# Function: convert from decimal degrees to degrees, minutes, seconds.\n",
    "def deg_to_dms(row, sphere=''):\n",
    "    if sphere == 'Latitude':\n",
    "        deg = row['Latitude']\n",
    "    if sphere == 'Longitude':\n",
    "        deg = row['Longitude']\n",
    "    m, s = divmod(abs(deg)*3600, 60)\n",
    "    d, m = divmod(m, 60)\n",
    "    if deg < 0:\n",
    "        d = -d\n",
    "    d, m = int(d), int(m)\n",
    "    s = round(s,2)\n",
    "    return f\"{d}Â° {m}' {s}\\\"\"\n",
    "\n",
    "# Apply the user-defined function to every row\n",
    "gdf_hotSpots['Lat_DMS'] = gdf_hotSpots.apply(lambda row: deg_to_dms(row, sphere='Latitude'), axis=1)\n",
    "gdf_hotSpots['Long_DMS'] = gdf_hotSpots.apply(lambda row: deg_to_dms(row, sphere='Longitude'), axis=1)\n",
    "\n",
    "#export geodataframe as shapefile\n",
    "gdf_hotSpots.to_file(f'{deliverablesDir}/Hotspots/{hotspotsFileName}.shp')\n",
    "hotspots_count1 = len(gdf_hotSpots)\n",
    "\n",
    "print(\"COMPLETED - Hotspot files were generated successfully\")\n",
    "#gdf_hotSpots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 7 ### Open validation and mapping environment\n",
    "\n",
    "os.system(\"start \" + f'{productionDirectory}/{delivery_date}/{fireID}_{delivery_date}/{fireID}_{delivery_date}.qgz')\n",
    "print(\"COMPLETED - mapping environment opened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYST ACTION: validate hotspots\n",
    "<p>0. Open layers thermal img, recent_perimeter, hotspots, breadcrumb (in that order) to map</p>\n",
    "<p>1. Remove outliers from the hotspots file</p>\n",
    "<p>2. (if hotspotting) Turn HotspotID column into consecutive numbers. In field calculator, \"update existing field\" - \"@row_number\" in expression box</p>\n",
    "<p>3. Save feature edits</p>\n",
    "<p>4. Leave QGIS workspace open</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 8 ### Create final hotspot files\n",
    "\n",
    "#Validation: check if number of hotspots changed\n",
    "gdf_hotSpots = geopandas.read_file(f'{deliverablesDir}/Hotspots/{hotspotsFileName}.shp')\n",
    "hotspots_count2 = len(gdf_hotSpots)\n",
    "if hotspots_count1 == hotspots_count2:\n",
    "    def prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk))\n",
    "    prRed('Hotspot count is the same as before editing.')\n",
    "    prRed(\"Did you forget to save edits to the hotspots in QGIS? If all hotspots were valid, proceed.\")\n",
    "\n",
    "#Export hotSpots CSV deliverable\n",
    "df_hotSpots = pandas.DataFrame(gdf_hotSpots.drop(columns='geometry'))\n",
    "df_hotSpots.to_csv(f'{deliverablesDir}/Hotspots/{hotspotsFileName}.csv')\n",
    "\n",
    "## Build data table and colorize KML file\n",
    "kml = simplekml.Kml(open=1)\n",
    "\n",
    "for index, row in df_hotSpots.iterrows():\n",
    "    pnt = kml.newpoint(name=row['HotspotID'])\n",
    "    pnt.extendeddata.newdata(name='HotspotID', value=row['HotspotID'])\n",
    "    pnt.extendeddata.newdata(name='HeatScore', value=row['HeatScore'])\n",
    "    pnt.extendeddata.newdata(name='Fire_Num', value=row['Fire_Num'])\n",
    "    pnt.extendeddata.newdata(name='Fire_Name', value=row['Fire_Name'])\n",
    "    pnt.extendeddata.newdata(name='CaptureDat', value=row['CaptureDat'])\n",
    "    pnt.extendeddata.newdata(name='CaptureTim', value=row['CaptureTim'])\n",
    "    pnt.extendeddata.newdata(name='Agency', value=row['Agency'])\n",
    "    pnt.extendeddata.newdata(name='Comments', value=row['Comments'])\n",
    "    pnt.extendeddata.newdata(name='Contact', value=row['Contact'])\n",
    "    pnt.extendeddata.newdata(name='Phone', value=row['Phone'])\n",
    "    pnt.extendeddata.newdata(name='Email', value=row['Email'])\n",
    "    pnt.extendeddata.newdata(name='Lat_DMS', value=row['Lat_DMS'])\n",
    "    pnt.extendeddata.newdata(name='Long_DMS', value=row['Long_DMS'])\n",
    "    pnt.coords = [(row['Longitude'], row['Latitude'])]\n",
    "    pnt.style.labelstyle.scale = 0\n",
    "    pnt.style.iconstyle.icon.href = 'http://maps.google.com/mapfiles/kml/shapes/shaded_dot.png'\n",
    "    pnt.style.iconstyle.scale = 0.5\n",
    "    if row['HeatScore'] >= 55.0:\n",
    "        pnt.style.iconstyle.color = simplekml.Color.red\n",
    "    elif row['HeatScore'] >= 26.0:\n",
    "        pnt.style.iconstyle.color = simplekml.Color.orange #'ff0000ff'\n",
    "    elif row['HeatScore'] >= 12.0:\n",
    "        pnt.style.iconstyle.color = simplekml.Color.yellow #'ff00a5ff'\n",
    "    else:\n",
    "        pnt.style.iconstyle.color = simplekml.Color.yellow #'ff00ffff'\n",
    "\n",
    "kml.save(f'{deliverablesDir}/Hotspots/{hotspotsFileName}.kml')\n",
    "\n",
    "print(\"COMPLETED - valid hotspots KML, SHP and CSV files were generated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYST ACTION: If no perimeter update is needed, jump to map prodution section (starting at Block 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 9 ### Import hotspot geometries\n",
    "\n",
    "## Make point geometry object from hotspots\n",
    "import shapely\n",
    "multiPointList = []\n",
    "for x in range(len(gdf_hotSpots)):\n",
    "    li = (shapely.get_x(gdf_hotSpots.geometry[x]), shapely.get_y(gdf_hotSpots.geometry[x]))\n",
    "    multiPointList.append(li)\n",
    "print(\"COMPLETED - analyst inspect object\")\n",
    "shapely.MultiPoint(multiPointList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYST ACTION: Calibrate alpha and buffer values for concave hull geometry build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 10 ### Calibrate values\n",
    "\n",
    "alpha = float(input(\"enter Alpha parameter (if empty, default = 0.02)\").strip() or 0.02)\n",
    "print(f\"Alpha parameter: {alpha}\")\n",
    "\n",
    "buffer_m = int(input(\"enter buffer parameter (if empty, default = 20m)\").strip() or 20)\n",
    "print(f\"Buffer parameter: {buffer_m}meters\")\n",
    "\n",
    "geometry_perimeter_hull = shapely.concave_hull(shapely.MultiPoint(multiPointList), ratio=alpha)\n",
    "geometry_perimeter_hull = shapely.buffer(geometry_perimeter_hull, buffer_m)\n",
    "gdf_new_perimeter = geopandas.GeoDataFrame(index=[0], crs=gdf_hotSpots.crs, geometry=[geometry_perimeter_hull])\n",
    "gdf_new_perimeter.to_file(f\"{masterFireDir}/Scratch/{fireID}_burning_zone.shp\")\n",
    "\n",
    "geometry_perimeter_hull"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYST ACTION: in QGIS manually correct burning area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 11 ### Rebuild geometry from cleaned burning zone shapefile\n",
    "\n",
    "# Make shape from recent perimeter shapefile\n",
    "if os.path.exists(f\"{recentFirePerimeterFilepath}\"):\n",
    "    with fiona.open(f\"{recentFirePerimeterFilepath}\") as shapefile:\n",
    "        # Iterate over the records\n",
    "        for record in shapefile:\n",
    "            # Get the geometry from the record\n",
    "            geometry_request_perim = shapely.geometry.shape(record['geometry'])\n",
    "else:\n",
    "    print(\"No request perimeter was submitted with this fire\")\n",
    "\n",
    "# Make shape from burning zone shapefile\n",
    "with fiona.open(f\"{masterFireDir}/Scratch/{fireID}_burning_zone.shp\") as shapefile:\n",
    "    # Iterate over the records\n",
    "    for record in shapefile:\n",
    "        # Get the geometry from the record\n",
    "        geometry_burning_zone = shapely.geometry.shape(record['geometry'])\n",
    "print(\"Inspect final burning zone geometry\")\n",
    "geometry_burning_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 12 ### Union perimeters and export final shapefiles\n",
    "\n",
    "## Union recent perimeter and burning_zone\n",
    "if os.path.exists(f\"{recentFirePerimeterFilepath}\"):\n",
    "    if shapely.get_type_id(geometry_request_perim) == 6 or shapely.get_type_id(geometry_request_perim) == 3:\n",
    "        geometry_perimeter = shapely.ops.unary_union([geometry_request_perim, geometry_burning_zone])\n",
    "    else:\n",
    "        geometry_perimeter = geometry_burning_zone\n",
    "else:\n",
    "    geometry_perimeter = geometry_burning_zone\n",
    "\n",
    "## Attribute Perimeter\n",
    "gdf_new_perimeter = geopandas.GeoDataFrame(index=[0], crs=gdf_hotSpots.crs, geometry=[geometry_perimeter])\n",
    "perimeter_area = gdf_new_perimeter['geometry'].area/ 10**4\n",
    "perimeter_length = gdf_new_perimeter['geometry'].length\n",
    "\n",
    "# Add constant columns\n",
    "templateColumns = {\n",
    "    'FIRENUMBER': f'{fireID}-2023',\n",
    "    'FIRE_NUMBE': f'{fireID}',\n",
    "    'FIRE_CLASS': 'E',\n",
    "    'BURNCODE': '',\n",
    "    'BURN_CLASS': '',\n",
    "    'HECTARES_U': int(perimeter_area.iloc[0]),\n",
    "    'PERIM_m': int(perimeter_length.iloc[0]),\n",
    "    'YEAR_DATE': '2023',\n",
    "    'ALIAS': fireName,\n",
    "    'CAPTURE_DA': scan_date_raw.strftime('%d-%b-%y'),\n",
    "    'CLOCK': captureTime,\n",
    "    'SOURCE': 6,\n",
    "    'SOURCE_AGENCY': 'Verimap Plus Inc',\n",
    "}\n",
    "\n",
    "for pair in templateColumns:\n",
    "    gdf_new_perimeter[pair] = templateColumns[pair]\n",
    "gdf_new_perimeter.head()\n",
    "\n",
    "## Export SHP & KML\n",
    "gdf_new_perimeter.to_file(f\"{deliverablesDir}/Perimeter/{perimeterFileName}.shp\")\n",
    "if os.path.exists(f'{deliverablesDir}/Perimeter/{perimeterFileName}.kml'):\n",
    "    os.remove(f'{deliverablesDir}/Perimeter/{perimeterFileName}.kml')\n",
    "gdf_new_perimeter.to_file(f'{deliverablesDir}/Perimeter/{perimeterFileName}.kml', driver='KML')\n",
    "\n",
    "os.system(f\"open -a 'qgis' {deliverablesDir}/Perimeter/{perimeterFileName}.shp\")\n",
    "print(\"COMPLETED - final shapefiles produced\")\n",
    "geometry_perimeter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYST ACTION: Go make final maps in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 13 ### Run to copy text to clipboard for map layout info box\n",
    "\n",
    "import pyperclip\n",
    "x = scan_date_raw.strftime('%b %d %Y').upper()\n",
    "fire_details_string = f\"Fire Scan Code:\\n{fireID}{delivery_date}\\n\\nAlias:\\n{fireName}\\n\\nDate of Acquisition:\\n{x}\\n\\nTime of Acquisition:\\n{captureTime[:2]}:{captureTime[2:]}\"\n",
    "pyperclip.copy(fire_details_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Block 14 ### Zip and export client package\n",
    "\n",
    "## folder path\n",
    "month_numeric = datetime.date.today().strftime('%m')\n",
    "month_literal = datetime.date.today().strftime('%B')\n",
    "day_numeric = datetime.date.today().strftime('%d')\n",
    "gdrive_deliverables = f'{gdrive}/{month_numeric}_{month_literal}/{month_literal.upper()}_{day_numeric}/'\n",
    "\n",
    "# Remove if already loaded to gdrive\n",
    "if os.path.exists(f'{gdrive_deliverables}{fireID}.zip'):\n",
    "    os.remove((f'{gdrive_deliverables}{fireID}.zip'))\n",
    "\n",
    "# remove .xml file\n",
    "for root, dirs, files in os.walk(f'{deliverablesDir}'):\n",
    "    for name in files:\n",
    "        if name.endswith('.xml'):\n",
    "            os.remove(os.path.join(root, name))\n",
    "  \n",
    "# Remove perimeter folder if empty\n",
    "if os.path.exists(f'{deliverablesDir}/Perimeter'):\n",
    "    if len(os.listdir(f'{deliverablesDir}/Perimeter')) == 0: \n",
    "        shutil.rmtree(f'{deliverablesDir}/Perimeter')\n",
    "# Remove hotspot folder if empty\n",
    "if os.path.exists(f'{deliverablesDir}/Hotspots'):\n",
    "    if len(os.listdir(f'{deliverablesDir}/Hotspots')) == 0: \n",
    "        shutil.rmtree(f'{deliverablesDir}/Hotspots')\n",
    "\n",
    "shutil.make_archive(deliverablesDir, 'zip', deliverablesDir)\n",
    "shutil.move(f\"{deliverablesDir}.zip\", f'{gdrive_deliverables}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
